{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gfrqSXdehYl"
      },
      "source": [
        "# Bayesian approaches homework - 60 points total\n",
        "\n",
        "## Part 1:  Bayesian Tomatoes (40 points)\n",
        "\n",
        "In this part of the assignment, you'll implement the final part of a Naive Bayes classifier that performs sentiment analysis on sentences from movie reviews.  Upload and read the train.tsv file that contains sentences and phrases that have been rated 0 to 4 for sentiment ranging from very negative to very positive.  We'll only be working with the full sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2bauf2z6DmW"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload() # upload train.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLls4yAXC2xK"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')  # Data for tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VnrdxYu6HXD"
      },
      "outputs": [],
      "source": [
        "with open('train.tsv', 'r') as textfile:\n",
        "  ratings_data = textfile.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjQUhiDhAZP2"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenize(sentence):\n",
        "    \"\"\" Returns list of tokens (strings) from the sentence.\n",
        "\n",
        "    Sets to lowercase and runs NLTK tokenizer.\n",
        "\n",
        "    Args:\n",
        "        sentence (string):  the string to tokenize\n",
        "    \"\"\"\n",
        "    return [t.lower() for t in word_tokenize(sentence)]\n",
        "\n",
        "class ModelInfo:\n",
        "    \"\"\" Contains all counts from the data necessary to do Naive Bayes.\n",
        "\n",
        "    Attributes:\n",
        "        word_counts (List[Dict[string,int]]):  counts of tokens, indexed by class\n",
        "        sentiment_counts (List[int]):  counts of sentences with each sentiment\n",
        "        total_words (List[int]):  counts of words in each sentiment\n",
        "        total_examples (int):  total sentence count\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word_counts = [{}, {}, {}, {}, {}]\n",
        "        self.sentiment_counts = [0, 0, 0, 0, 0]\n",
        "        self.total_words = [0, 0, 0, 0, 0]\n",
        "        self.total_examples = 0\n",
        "\n",
        "\n",
        "    def update_word_counts(self, sentence, sentiment):\n",
        "        \"\"\" Consume a sentence and update all counts.\n",
        "\n",
        "        To \"tokenize\" the sentence we'll make use of NLTK, a widely-used Python natural language\n",
        "        processing (NLP) library.  This will handle otherwise onerous tasks like separating periods\n",
        "        from their attached words.  (Unless the periods are decimal points ... it's more complex\n",
        "        than you might think.)  The result of tokenization is a list of individual strings that are\n",
        "        words or their equivalent.\n",
        "\n",
        "        Args:\n",
        "            sentence (string):  The example sentence.\n",
        "            sentiment (int):  The sentiment label.\n",
        "        \"\"\"\n",
        "\n",
        "        # Get the relevant dicts for the sentiment\n",
        "        s_word_counts = self.word_counts[sentiment]\n",
        "        tokens = tokenize(sentence)\n",
        "        for token in tokens:\n",
        "            self.total_words[sentiment] += 1\n",
        "            s_word_counts[token] = s_word_counts.get(token, 0) + 1\n",
        "\n",
        "FIRST_SENTENCE_NUM = 1\n",
        "\n",
        "def get_models(ratings_data):\n",
        "    \"\"\"Returns a model_info object, consuming a string for examples.\"\"\"\n",
        "    next_fresh = FIRST_SENTENCE_NUM\n",
        "    info = ModelInfo()\n",
        "    for line in ratings_data.splitlines():\n",
        "        if line.startswith(\"---\"):\n",
        "            return info\n",
        "        fields = line.split(\"\\t\")\n",
        "        try:\n",
        "            sentence_num = int(fields[1])\n",
        "            if sentence_num <= next_fresh:\n",
        "                continue\n",
        "            next_fresh += 1\n",
        "            sentiment = int(fields[3])\n",
        "            info.sentiment_counts[sentiment] += 1\n",
        "            info.total_examples += 1\n",
        "            info.update_word_counts(fields[2], sentiment)\n",
        "        except ValueError:\n",
        "            # Some kind of bad input?  Unlikely with our provided data\n",
        "            continue\n",
        "    return info\n",
        "\n",
        "model_info = get_models(ratings_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-T9BI1RFCOK"
      },
      "source": [
        "**(1, 30 points)** Complete naive_bayes_classify(), below.  It should take a ModelInfo object and use the counts stored therein to give the most likely class according to a Naive Bayes calculation, and the log likelihood of that class.  For priors on the sentiment, use the actual frequencies with which each sentiment is used.  Notice that there are 5 different classes to compare.  Use the OUT_OF_VOCAB_PROB constant for any tokens that haven't been seen for a particular sentiment in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVH8TO7dDZlX"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "CLASSES = 5\n",
        "OUT_OF_VOCAB_PROB = 0.0000000001\n",
        "\n",
        "\"\"\" naive_bayes_classify:  takes a ModelInfo containing all counts necessary for classsification\n",
        "    and a String to be classified.  Returns a number indicating sentiment and a log probability\n",
        "    of that sentiment (two comma-separated return values).\n",
        "\"\"\"\n",
        "def naive_bayes_classify(info, sentence):\n",
        "    \"\"\" Use a Naive Bayes model to return sentence's most likely classification and the log prob.\n",
        "\n",
        "    Args:\n",
        "        info (ModelInfo):  a ModelInfo containing the counts from the training data\n",
        "        sentence (string):  the test sentence to classify\n",
        "\n",
        "    Returns:\n",
        "        int for the best sentiment\n",
        "        float for the best log probability (unscaled, just log(prior * product of cond. probs))\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    return best_class, best_log_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laPUyW3mGDnR"
      },
      "outputs": [],
      "source": [
        "# Tests\n",
        "print(naive_bayes_classify(model_info, \"I hate this movie\")) # Should return 0, -25.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0nm828N8VC_"
      },
      "outputs": [],
      "source": [
        "print(naive_bayes_classify(model_info, \"A joyous romp\"))    # Should return 4, -22.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLlIdvFU8NNF"
      },
      "outputs": [],
      "source": [
        "print(naive_bayes_classify(model_info, \"notaword\")) # Should return 3, -24.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CXn5RzS5A7s"
      },
      "source": [
        "**2, 10 points)** Naive Bayes is sometimes called a \"linear\" classifier; let's explore why.  Suppose I have two classes $C_1$ and $C_2$ and two observable features A and B; each feature can take on 3 values.  Feature A's conditional distribution is [1/2, 1/4, 1/4] for class 1, [1/4, 1/4, 1/2] for class 2.  Feature B's conditional distribution is [1/4, 1/2, 1/4] for class 1, [1/2, 1/4, 1/4] for class 2.  The two classes each have a prior of 1/2.  Given boolean values (i.e. valued 0 or 1) $a_0$, $a_1$, $a_2$ and $b_0$, $b_1$, $b_2$ to represent the observations of feature A and B, derive an equation for each class that gives the log likelihood of that class given the observations.  (Use base 2 for your logs to make the equations simpler.)  Then, use these log likelihoods to come up with a linear inequality (a weighted sum of $a_0, \\ldots, b_2$ that is compared to a constant) that decides whether an example belongs to class 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M11qIO25A7u"
      },
      "source": [
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z-tE4ZAemNE"
      },
      "source": [
        "## Part 2:  Bayesian Networks in Practice (20 points)\n",
        "\n",
        "Bayesian networks can capture complex probabilistic relationships and model uncertainty about a variety of aspects of the situation.  \"Bayesian statistics\" often makes use of them, combining a statistician's knowledge of what distributions occur in nature with Bayesian reasoning about uncertainty given evidence and Bayesian networks' potentially complex relationships between variables.\n",
        "\n",
        "Here, you'll just answer questions about the example at https://www.pymc.io/projects/examples/en/latest/case_studies/BEST.html, a common example used by a Bayesian psychology researcher (Kruschke) to show that Bayesian methods have advantages over traditional statistical hypothesis testing.  The code for this example is reproduced below.  You don't need to decipher everything, but you may need to reference the webpage or do additional digging to answer the questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5t-cLeK5A7w"
      },
      "outputs": [],
      "source": [
        "# Consider running in Google Colab even if you don't usually -\n",
        "# installing these libraries can cause headaches, and Colab\n",
        "# already has them installed\n",
        "#!pip install arviz\n",
        "#!pip install pymc\n",
        "\n",
        "import arviz as az\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pymc as pm\n",
        "import seaborn as sns\n",
        "\n",
        "rng = np.random.default_rng(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEJnjJzY5A7x"
      },
      "outputs": [],
      "source": [
        "iq_drug = np.array([\n",
        "    101, 100, 102, 104, 102, 97, 105, 105, 98, 101, 100, 123, 105, 103,\n",
        "    100, 95, 102, 106, 109, 102, 82, 102, 100, 102, 102, 101, 102, 102,\n",
        "    103, 103, 97, 97, 103, 101, 97, 104, 96, 103, 124, 101, 101, 100,\n",
        "    101, 101, 104, 100, 101\n",
        "])\n",
        "\n",
        "iq_placebo = np.array([\n",
        "    99, 101, 100, 101, 102, 100, 97, 101, 104, 101, 102, 102, 100, 105,\n",
        "    88, 101, 100, 104, 100, 100, 100, 101, 102, 103, 97, 101, 101, 100,\n",
        "    101, 99, 101, 100, 100, 101, 100, 99, 101, 100, 102, 99, 100, 99\n",
        "])\n",
        "\n",
        "df1 = pd.DataFrame({\"iq\": iq_drug, \"group\": \"drug\"})\n",
        "df2 = pd.DataFrame({\"iq\": iq_placebo, \"group\": \"placebo\"})\n",
        "indv = pd.concat([df1, df2]).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yunJD_g15A7x"
      },
      "outputs": [],
      "source": [
        "mu_m = indv.iq.mean()\n",
        "mu_s = indv.iq.std() * 2\n",
        "\n",
        "with pm.Model() as model:\n",
        "    group1_mean = pm.Normal(\"group1_mean\", mu=mu_m, sigma=mu_s)\n",
        "    group2_mean = pm.Normal(\"group2_mean\", mu=mu_m, sigma=mu_s)\n",
        "\n",
        "sigma_low = 10**-1\n",
        "sigma_high = 10\n",
        "\n",
        "with model:\n",
        "    group1_std = pm.Uniform(\"group1_std\", lower=sigma_low, upper=sigma_high)\n",
        "    group2_std = pm.Uniform(\"group2_std\", lower=sigma_low, upper=sigma_high)\n",
        "\n",
        "    nu_minus_one = pm.Exponential(\"nu_minus_one\", 1 / 29.0)\n",
        "    nu = pm.Deterministic(\"nu\", nu_minus_one + 1)\n",
        "\n",
        "with model:\n",
        "    lambda_1 = group1_std**-2\n",
        "    lambda_2 = group2_std**-2\n",
        "    group1 = pm.StudentT(\"drug\", nu=nu, mu=group1_mean, lam=lambda_1, observed=iq_drug)\n",
        "    group2 = pm.StudentT(\"placebo\", nu=nu, mu=group2_mean, lam=lambda_2, observed=iq_placebo)\n",
        "\n",
        "with model:\n",
        "    diff_of_means = pm.Deterministic(\"difference of means\", group1_mean - group2_mean)\n",
        "    diff_of_stds = pm.Deterministic(\"difference of stds\", group1_std - group2_std)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with model:\n",
        "    idata = pm.sample()"
      ],
      "metadata": {
        "id": "yy2IVIF059NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_posterior(\n",
        "    idata,\n",
        "    var_names=[\"difference of means\", \"difference of stds\"],\n",
        "    ref_val=0,\n",
        "    hdi_prob=0.95,\n",
        ");"
      ],
      "metadata": {
        "id": "EB8x1GYlEG0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3, 9 points)** Draw the Bayesian network that is implied by this model - shading circles that represent observed data, putting a box around any circles representing variables that are repeated, and drawing arrows that represent conditional dependence.  The variables you are trying to connect are group1_mean, group2_mean, group1_std, group2_std, nu, iq_drug, iq_placebo, difference_of_means, and difference_of_stds.  (The other values you see are either constants or not important. lambda1 and lambda2 are just transforming standard deviations to precisions, and you can just assume a direct connection through them instead.  *Please submit an image file containing your drawing along with your notebook, even if you try to embed it, as a backup.)*"
      ],
      "metadata": {
        "id": "DuKRj2fTIaQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**"
      ],
      "metadata": {
        "id": "aiT06m7VKZzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4, 3 points)** Alter the plot_posterior call slightly so that you can find out the probability that the difference in means between the populations is at least 2.  (Hint:  It's currently showing the probability mass on either side of 0.)"
      ],
      "metadata": {
        "id": "S5jtwDJbnXgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**"
      ],
      "metadata": {
        "id": "ZL1mvBtIpKYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **5, 8 points)** A concern we might have about a Bayesian model is that its assumptions about priors and distributions can be a bit arbitrary.  In the code box below, rerun the analysis, but make the following changes:\n",
        "\n",
        "* group 1 and group 2's means are uniformly distributed between 80 and 120.\n",
        "\n",
        "* group 1 and group 2's observations are now normally distributed, not $t$ distributions.  (The latter assumption is meant to protect against outliers, because $t$ distributions have long tails.)\n",
        "\n",
        "Recalculate the probability that the difference in means is at least 2."
      ],
      "metadata": {
        "id": "iAoe4V-UpgxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO copy and change the model"
      ],
      "metadata": {
        "id": "JbkhAeoFtcY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with model:\n",
        "    idata = pm.sample()"
      ],
      "metadata": {
        "id": "DI9TYN3fuIv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO copy your modified plot_posterior call here"
      ],
      "metadata": {
        "id": "KX6mn3sJuPFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO what is the likelihood of a difference of at least 2 with this model?**\n",
        "\n"
      ],
      "metadata": {
        "id": "JgxEm7v8tbN8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnwYi9lob0B1"
      },
      "source": [
        "**When you're done, use \"File->Download .ipynb\" and upload your .ipynb file to Blackboard, along with a PDF version (File->Print->Save as PDF) of your assignment.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2RaIpFOa9fFc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}